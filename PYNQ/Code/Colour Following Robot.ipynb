{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colour Detection Robot\n",
    "\n",
    "This workbook contains the code that controls a colour detecting and following robot.\n",
    "\n",
    "The following peripherals are attached to the PYNQ board:\n",
    "        • DC Motor\n",
    "        • TI L293 Half H-Driver\n",
    "        • Sharp GP2D120 proximity sensor\n",
    "        • Advent USB Webcam\n",
    "        • External Power Source\n",
    "        \n",
    "        \n",
    "This initial section of the workbook imports all of the modules required for the rest of the pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''from pynq import Overlay\n",
    "Overlay(\"base.bit\").download()'''\n",
    "#from pynq.drivers.video import Frame\n",
    "from pynq.iop import Arduino_IO\n",
    "from pynq.iop import ARDUINO\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image as PIL_Image\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this secion of the program the set up of the connected devices is carried out.\n",
    "\n",
    "The pins of the motor controller and ultrasonic sensor are defined using the PYNQ's Arduino_IO module.\n",
    "\n",
    "The pixel width and height of the USB webcam is set and the image capture from the webcam begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capture device is open: True\n"
     ]
    }
   ],
   "source": [
    "#Motor 1\n",
    "m1_enable = Arduino_IO(ARDUINO, 7, 'out')\n",
    "m1_left = Arduino_IO(ARDUINO, 6, 'out')\n",
    "m1_right = Arduino_IO(ARDUINO, 5, 'out')\n",
    "\n",
    "#Motor 2\n",
    "m2_enable = Arduino_IO(ARDUINO, 8, 'out')\n",
    "m2_left = Arduino_IO(ARDUINO, 9, 'out')\n",
    "m2_right = Arduino_IO(ARDUINO, 10, 'out')\n",
    "\n",
    "#Ultrasonic sensor 1\n",
    "TRIG1 = Arduino_IO(ARDUINO, 4, 'out')\n",
    "#ECHO1 = Arduino_IO(ARDUINO, 3, 'in')\n",
    "\n",
    "frame_in_w = 640\n",
    "frame_in_h = 480\n",
    "\n",
    "videoIn = cv2.VideoCapture(0)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, frame_in_w);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_in_h);\n",
    "\n",
    "print(\"capture device is open: \" + str(videoIn.isOpened()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the method that checks the distance ahead of the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDistance():\n",
    "    #global pulse_start, pulse_end, pulse_duration\n",
    "    pulse_start = 0\n",
    "    pulse_end = 0\n",
    "    pulse_duration = 0\n",
    "    print (\"Distance measurement in progress\")\n",
    "\n",
    "    distance = 0\n",
    "    TRIG1.write(0)\n",
    "    print (\"Waiting For Sensor #1 To Settle\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    TRIG1.write(1)\n",
    "    time.sleep(0.00001)\n",
    "    TRIG1.write(0)\n",
    "    \n",
    "    while ECHO1.read() == 0:\n",
    "        pulse_start = time.time()\n",
    "\n",
    "    while ECHO1.read() == 1: \n",
    "        pulse_end = time.time()\n",
    "    \n",
    "    try:\n",
    "        pulse_duration = pulse_end - pulse_start\n",
    "        distance = pulse_duration * 17150\n",
    "\n",
    "        distance = round(distance, 2)    \n",
    "    \n",
    "        return distance\n",
    "        \n",
    "    except UnboundLocalError:\n",
    "        print(\"Error\", end = '\\r')\n",
    "        pass\n",
    "    \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the function that contains the invinate while loop that detects the above colour in the webcam's image and controls the robot's motors depending if and where in the image the desired colour is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def colour_follower (b):\n",
    "    try:\n",
    "\n",
    "        #Takes in the value that the user has seleced using the sliders and sets those values as the \n",
    "        #upper and lower values for the pixel detection\n",
    "        lower = np.array([lower_hue.value, lower_saturation.value, lower_value.value], dtype = \"uint8\")\n",
    "        upper = np.array([upper_hue.value, upper_saturation.value, upper_value.value], dtype = \"uint8\")\n",
    "\n",
    "\n",
    "        frame_number = 0\n",
    "\n",
    "        while(True): \n",
    "            \n",
    "        #for i in range(0,10):\n",
    "            \n",
    "            m1_enable.write(0) #Motor #1 enable pin\n",
    "            m2_enable.write(0) #Motor #1 enable pin\n",
    "\n",
    "            #Reads in new frame from camera\n",
    "            ret, frame_vga = videoIn.read()\n",
    "            startTime = time.time()\n",
    "            #Converts frame to HSV format and creates a mask using the upper and lower colour settings\n",
    "            converted = cv2.cvtColor(frame_vga, cv2.COLOR_BGR2HSV)\n",
    "            skinMask = cv2.inRange(converted, lower, upper)\n",
    "\n",
    "            #Elliptical structuring kernel created and two iterations of erosions and dilations are carried\n",
    "            #out to reduce the risk of any pixels being falsely detected as skin\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "            skinMask = cv2.erode(skinMask, kernel, iterations = 2)\n",
    "            skinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n",
    "\n",
    "            #Apply gaussian blurring to the mask to reduce any noise before appling the mask to the frame\n",
    "            skinMask = cv2.GaussianBlur(skinMask, (3, 3), 0)\n",
    "            skin = cv2.bitwise_and(frame_vga, frame_vga, mask = skinMask)\n",
    "\n",
    "            #Divide the original image into three equal parts, left, center and right\n",
    "            left = frame_vga[0:480, 0:213]\n",
    "            center = frame_vga[0:480, 213:426]\n",
    "            right = frame_vga[0:480, 426:680]\n",
    "\n",
    "            #Divide the mask into three equal parts, left, center and right\n",
    "            left_skin = skinMask[0:480, 0:213]\n",
    "            center_skin = skinMask[0:480, 213:426]\n",
    "            right_skin = skinMask[0:480, 426:680]\n",
    "\n",
    "            #Display the left section of the image\n",
    "            #plt.imshow(left_skin)\n",
    "            #plt.show()\n",
    "\n",
    "            #Calculate and print the percentage of pixels detected as skin versus the total number\n",
    "            #of pixels within this section of the frame\n",
    "            lft_blkpxls = round(cv2.countNonZero(left_skin)/(640*480)*100, 2)\n",
    "            print(\"Percentage of non-black pixels in left: \", lft_blkpxls)\n",
    "\n",
    "            #Display the center section of the image\n",
    "            #plt.imshow(center_skin)\n",
    "            #plt.show()\n",
    "\n",
    "            #Calculate and print the percentage of pixels detected as skin versus the total number\n",
    "            #of pixels within this section of the frame\n",
    "            center_blkpxls = round(cv2.countNonZero(center_skin)/(640*480)*100, 2)\n",
    "            print(\"Percentage of non-black pixels in center: \", center_blkpxls)\n",
    "\n",
    "            #Display the right section of the image\n",
    "            #plt.imshow(right_skin)\n",
    "            #plt.show()\n",
    "\n",
    "            #Calculate and print the percentage of pixels detected as skin versus the total number\n",
    "            #of pixels within this section of the frame\n",
    "            rgt_blkpxls = round(cv2.countNonZero(right_skin)/(640*480)*100, 2)\n",
    "            print(\"Percentage of non-black pixels in right: \", rgt_blkpxls)\n",
    "\n",
    "\n",
    "            plt.imshow(np.hstack([frame_vga, skin]))\n",
    "            #plt.imshow(skin)\n",
    "            plt.show()\n",
    "\n",
    "            #Calculate and print the percentage of pixels detected as skin versus \n",
    "            #the total number of pixels in the frame\n",
    "            frameArray = skinMask[0:480, 0:680]\n",
    "            totalblkpxls =  round(cv2.countNonZero(frameArray)/(640*480)*100, 2)\n",
    "            print(\"Percentage of non-black pixels: \", totalblkpxls)\n",
    "\n",
    "            #Outputs the frame number\n",
    "            frame_number = frame_number + 1\n",
    "            print(\"Frame Number: \", frame_number)\n",
    "            endTime = time.time()\n",
    "            \n",
    "            \n",
    "            totalTime = endTime - startTime\n",
    "            \n",
    "            print((1/totalTime), \" FPS\")\n",
    "            \n",
    "            # Allow 5 frames for callibration\n",
    "            if frame_number > 5:\n",
    "                #If the percentage of pixels is below 10%, the robot will not move\n",
    "                if(totalblkpxls < 5):\n",
    "                    print(\"Not enough colour to follow....adjusting\")\n",
    "                    m1_enable.write(1) #enable\n",
    "                    m1_left.write(0)\n",
    "                    m1_right.write(1)\n",
    "\n",
    "                    m2_enable.write(1) #enable\n",
    "                    m2_left.write(1)\n",
    "                    m2_right.write(0)\n",
    "                    time.sleep(0.5)\n",
    "                else:\n",
    "                    distanceAhead = 11\n",
    "                    #distanceAhead = getDistance()\n",
    "                    print(\"Distance Ahead\", distanceAhead)\n",
    "                    print(\"Above Threshold\")\n",
    "\n",
    "                    if distanceAhead < 0 or distanceAhead > 500:\n",
    "                        print(\"Sensor Malfunction - Sensor Reading:\", distanceAhead)\n",
    "                    elif distanceAhead < 10:\n",
    "                        print(\"Path obstructed, object\", distanceAhead, \" away\")\n",
    "                    else:\n",
    "                        print(\"Path clear\")\n",
    "                        #If the majority of the detected pixels are in the left section of the \n",
    "                        #frame, the robot will adjust itself and move towards the detected colour\n",
    "                        if (lft_blkpxls > center_blkpxls and lft_blkpxls > rgt_blkpxls):\n",
    "                            print(\"Adjusting Left\")\n",
    "                            m1_enable.write(1) #enable\n",
    "                            m1_left.write(0)\n",
    "                            m1_right.write(1)\n",
    "\n",
    "                            m2_enable.write(1) #enable\n",
    "                            m2_left.write(1)\n",
    "                            m2_right.write(0)\n",
    "\n",
    "                            time.sleep(0.25)\n",
    "\n",
    "                            m1_enable.write(1) #enable\n",
    "                            m1_left.write(0)\n",
    "                            m1_right.write(1)\n",
    "\n",
    "                            m2_enable.write(1) #enable\n",
    "                            m2_left.write(0)\n",
    "                            m2_right.write(1)\n",
    "\n",
    "                            time.sleep(2)\n",
    "\n",
    "                        #If the majority of the detected pixels are in the center section of the \n",
    "                        #frame, the robot will move towards the detected colour    \n",
    "                        elif(center_blkpxls > lft_blkpxls and center_blkpxls > rgt_blkpxls):\n",
    "                            print(\"Going Straight Ahead\")\n",
    "                            m1_enable.write(1) #enable\n",
    "                            m1_left.write(0)\n",
    "                            m1_right.write(1)\n",
    "\n",
    "                            m2_enable.write(1) #enable\n",
    "                            m2_left.write(0)\n",
    "                            m2_right.write(1)\n",
    "\n",
    "                            time.sleep(2)\n",
    "\n",
    "                        #If the majority of the detected pixels are in the right section of the \n",
    "                        #frame, the robot will adjust itself and move towards the detected colour\n",
    "                        elif(rgt_blkpxls > center_blkpxls and rgt_blkpxls > lft_blkpxls):\n",
    "                            print(\"Adjusting Right\")\n",
    "                            m1_enable.write(1) #enable\n",
    "                            m1_left.write(1)\n",
    "                            m1_right.write(0)\n",
    "\n",
    "                            m2_enable.write(1) #enable\n",
    "                            m2_left.write(0)\n",
    "                            m2_right.write(1)\n",
    "\n",
    "                            time.sleep(0.25)\n",
    "\n",
    "                            m1_enable.write(1) #enable\n",
    "                            m1_left.write(0)\n",
    "                            m1_right.write(1)\n",
    "\n",
    "                            m2_enable.write(1) #enable\n",
    "                            m2_left.write(0)\n",
    "                            m2_right.write(1)\n",
    "\n",
    "                            time.sleep(2)\n",
    "                        #Default case    \n",
    "                        else:\n",
    "                            print(\"Default\")\n",
    "                            time.sleep(2)\n",
    "            \n",
    "            else:\n",
    "                print(\"Calibrating\")\n",
    "            \n",
    "            #Wait here until the image is cleared\n",
    "            clear_output(wait=True)\n",
    "    except KeyboardInterrupt:\n",
    "        videoIn.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the range of the pixel colours that the webcam will detect are set (HSV format):\n",
    "    - skin is a difficult colour to detect because of light conditions and different skin tones so a \n",
    "    slider is setup so the user can select the range they want to detect.\n",
    "    \n",
    "    - the sliders were initially used to find the range of values which represent skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower_hue = widgets.IntSlider(min=0, max=179, value=0, description = \"Lower Hue\")\n",
    "lower_saturation = widgets.IntSlider(min=0, max=255, value=48, description = \"Lower Saturation\")\n",
    "lower_value = widgets.IntSlider(min=0, max=255, value=80, description = \"Lower Value\")\n",
    "\n",
    "upper_hue = widgets.IntSlider(min=0, max=179, value=20, description = \"Upper Hue\")\n",
    "upper_saturation = widgets.IntSlider(min=0, max=255, value=255, description = \"Upper Saturation\")\n",
    "upper_value = widgets.IntSlider(min=0, max=255, value=255, description = \"Upper Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets up the button that starts the colour following robot and sets up the sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slider_container = widgets.HBox([widgets.VBox([lower_hue, lower_saturation, lower_value]), \n",
    "      \n",
    "      widgets.VBox([upper_hue, upper_saturation, upper_value])], background_color='#EEE')\n",
    "\n",
    "strt_colourfollower = widgets.Button(description=\"Start\")\n",
    "strt_colourfollower.width = \"120px\"\n",
    "strt_colourfollower.background_color = \"#FFFF00\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays the sliders and button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of non-black pixels in left:  0.0\n",
      "Percentage of non-black pixels in center:  0.0\n",
      "Percentage of non-black pixels in right:  0.0\n"
     ]
    }
   ],
   "source": [
    "strt_colourfollower.on_click(colour_follower)\n",
    "\n",
    "display.display(slider_container)\n",
    "display.display(strt_colourfollower)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  },
  "widgets": {
   "state": {
    "01b79c815e394418b7585236f3455cb8": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "1f7f1ee2cbc3417883e6f315e1aff2d8": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "3a9a90fd14c247ae8499aefc761a8655": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "43c198703e334330bc764e38f9afd4f8": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "671860f53f1d4224a2f52c71dfa84724": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "72ee030ce37a4c90bc6814b4979e6098": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "9dee5ff538bb4351ab74e9a06b077d18": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "a08a49cb8fdb4b23be4daf5fd42b9a8a": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "a99a034366da4f02949d002c16778524": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
